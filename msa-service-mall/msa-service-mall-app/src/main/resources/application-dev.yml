spring:
  cloud:
    # 命名服务 & 配置服务
    nacos:
      server-addr: ${NACOS_SERVER_ADDR:localhost:28848}
      discovery:
        namespace: ${NAMESPACE:dev}
        group: MSA-ACTION
#    loadbalancer:    #TODO
#      cache:
#        caffeine:
#          spec:
  #      config:
  #        namespace: ${NAMESPACE:dev}
  #        group: GATEWAY-SAMPLE
  #        name:                 # 使用的 Nacos 配置集的 dataId，默认为 spring.application.name
  #        file-extension: yaml  # 配置文件格式

  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    driver-class-name: com.mysql.cj.jdbc.Driver
    # 数据库命名包含多个单词官方建议使用下划线连接
    url: jdbc:mysql://localhost:23306/msa-action?useUnicode=true&characterEncoding=utf8&useSSL=false&serverTimezone=UTC
    username: root
    password: 123456
    druid:
      # 初始化连接数
      initial-size: 5
      # 连接池中最小的空闲连接数
      min-idle: 5
      # 连接吃中最大的活跃连接数
      max-active: 20
      # 连接等待最大时间
      max-wait: 60000
      # 检测连接池中空闲连接的时间间隔
      time-between-eviction-runs-millis: 60000
      # 连接在池中保持空闲的最长时间
      min-evictable-idle-time-millis: 300000
      # 用于检测连接是否有效的SQL语句
      validation-query: SELECT 1 FROM DUAL
      # 当连接处于空闲状态时，是否执行验证查询
      test-while-idle: true
      # 当从连接池中借用连接时，是否执行验证查询
      test-on-borrow: false
      # 当归还连接给连接池时，是否执行验证查询
      test-on-return: false
      # 是否使用预处理语句来提高性能
      pool-prepared-statements: true
      # 每个连接允许的最大预处理语句数量
      max-pool-prepared-statement-per-connection-size: 20
      # 连接池中连接的过滤器列表
      # filters: stat,wall,log4j
      filters: stat,wall
      # 连接属性设置：是否合并SQL语句，设置慢查询阈值
      connection-properties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=1000

  kafka:
    #kafka server的地址，集群配多个，中间，逗号隔开
    #连接
    bootstrap-servers: msa-kafka:9092
    producer:
      retries: 3
      #这里是按字节计算，不是消息个数，即 16384 bytes
      batch-size: 16384
      #32MB的批处理缓冲区，按照字节计算
      buffer-memory: 33554432
      #键的序列化器
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      #值的序列化器
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      #0:   生产者的消息在成功写入所有节点之前不会收到任何来自服务器的响应
      #1:   生产者的消息只需要成功写入Leader节点就会收到一个来自服务器的成功响应
      #all: 生产者的消息只有成功写入所有节点才会收到一个来自服务器的成功响应
      acks: 1
    consumer:
      #默认消费者组
      group-id: ${kafka.topic.group}
      #该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下该作何处理：
      #latest（默认值）在偏移量无效的情况下，消费者将从最新的记录开始读取数据（在消费者启动之后生成的记录）
      #earliest ：在偏移量无效的情况下，消费者将从起始位置读取分区的记录
      auto-offset-reset: earliest
      #批量一次最大拉取数据量
      max-poll-records: 4000
      #是否自动提交偏移量，默认值是true,为了避免出现重复数据和数据丢失，可以把它设置为false,然后手动提交偏移量
      enable-auto-commit: false
      #自动提交的时间间隔 在spring boot 2.X 版本中这里采用的是值的类型为Duration 需要符合特定的格式，如1S,1M,2H,5D
      auto-commit-interval: 1S
      #键的反序列化方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      #值的反序列化方式
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    listener:
      #在侦听器容器中运行的线程数
      concurrency: 5
      #listener负责ack，每调用一次，就立即commit
      ack-mode: manual_immediate
      missing-topics-fatal: false

kafka:
  topic:
    group: msa-action

redisson:
  config:
    host: 127.0.0.1
    port: 26379
    password: 123456
    pool-size: 10
    min-idle-size: 5
    idle-timeout: 30000
    connect-timeout: 5000
    retry-attempts: 3
    retry-interval: 1000
    ping-interval: 60000
    keep-alive: true

feign:
  client:
    config:
      default:
        connectTimeout: 3000
        readTimeout: 3000

logging:
  level:
    top.kwseeker.msa.action.user: debug